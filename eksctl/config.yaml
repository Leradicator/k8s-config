---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: cluster-v1
  region: eu-west-1
  version: "1.22"
vpc:
  id: vpc-0dba7a9519e237a69
  subnets:
    public:
      public-eu-west-1a:
        id: subnet-0c0197c036264a455
      public-eu-west-1b:
        id: subnet-07166e1aff0227b7e
    private:
      private-eu-west-1a:
        id: subnet-0ad2e0b2c32198ef5
      private-eu-west-1b:
        id: subnet-0b168bcca3e60e0a3
managedNodeGroups:
  - name: worker
    labels:
      role: worker
      env: dev
    availabilityZones: ["eu-west-1a", "eu-west-1b"]
    instanceType: t2.micro
    amiFamily: AmazonLinux2
    volumeSize: 30
    volumeName: /dev/xvda
    volumeType: gp3
    volumeIOPS: 3000
    volumeThroughput: 125
    volumeEncrypted: false
    desiredCapacity: 4
    minSize: 3
    maxSize: 5
    updateConfig:
      maxUnavailable: 1 # or `maxUnavailablePercentage: 75` to specify maxUnavailable as a percentage of total nodes
    privateNetworking: true
    ssh:
      allow: true
      publicKeyName: eu-west-1_vpckey
    tags:
      nodegroup-role: worker
      node-role.kubernetes.io/worker: "true"
      kubernetes.io/cluster/cluster-v1: "owned"
    iam:
      attachPolicyARNs:
        # EKS worker nodes require the following two policies at least
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
    subnets:
    - private-eu-west-1a
    - private-eu-west-1b
